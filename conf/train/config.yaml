defaults:
  - hydra/launcher: slurm
  - dataset: hammers

use_ddp: True
world_size: 1
rank: 0
local_rank: 0

n_epochs: 500
batch_size: 1 # samples sent through 1-by-1, step optimizer every batch_size samples, per-gpu
resume_ckpt: ''        # path to model checkpoint to resume
resume_ckpt_opt_state: ''
workers: 1
num_kp: 8
outf: '/root/checkpoint'
lr: 0.0001
num_cates: 1
category: 1       # category to train
num_points: 500   # number of point-cloud points in input

log_every_n_samples: 99
checkpoint_every_n_samples: 9900

loss_term_weights:
  loss_att_weight: 0.
  Kp_dis_weight: 3.0
  Kp_cent_dis_weight: 0.
  loss_rot_weight: 0.2
  loss_surf_weight: 3.0
  loss_sep_weight: 1.0

scale_loss_inputs_by: 0.01

slurm_additional:
  wandb_dir: '/root/checkpoint'
  python_bin: '/opt/conda/envs/6pack/bin/python'
  python_optstr: '-m torch.distributed.launch --nproc_per_node=${slurm_additional.gpus}'
  gpus: 7

slurm:
  gres: gpu:${slurm_additional.gpus}
  job_name:
    - 6pack-${dataset.name}-num_kp-${num_kp}-batch_size-${batch_size}-lr-{$lr}
  partition: gpu
  cpus_per_task: eval:4*${slurm_additional.gpus}
  ntasks_per_node: 1
  mem: eval:str(22*${slurm_additional.gpus})+ 'G'
  nodes: 1
  qos: normal

singularity:
  bin_path: '/h/dturpin/pkgs/bin/singularity'
  sbox_path: '/h/dturpin/img/6pack_sbox'
  binds:
    - '/checkpoint/dturpin/$SLURM_JOB_ID:/root/checkpoint'

exec_path: '/h/dturpin/repos/6-PACK/scripts/train.py'
